<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <link>/</link>
    <description>Recent content on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Gilles Kratzer</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0200</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Bayesian Network Modeling Applied to Feline Calicivirus Infection Among Cats in Switzerland</title>
      <link>/publication/fcv/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0100</pubDate>
      
      <guid>/publication/fcv/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Additive Bayesian Network Modelling with the R Package abn</title>
      <link>/publication/abn/</link>
      <pubDate>Wed, 20 Nov 2019 00:00:00 +0100</pubDate>
      
      <guid>/publication/abn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Additive Bayesian networks for antibiotic resistance and potential risk factors in Salmonella enterica isolates from layer hens in Uganda</title>
      <link>/publication/terence/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0200</pubDate>
      
      <guid>/publication/terence/</guid>
      <description></description>
    </item>
    
    <item>
      <title>mcmcabn</title>
      <link>/project/mcmcabn/</link>
      <pubDate>Sat, 27 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>/project/mcmcabn/</guid>
      <description>&lt;p&gt;Flexible implementation of a structural MCMC sampler for Directed Acyclic Graphs (DAGs). It supports the new edge reversal move from Grzegorczyk and Husmeier (2008) &lt;a href=&#34;doi:10.1007/s10994-008-5057-7&#34; target=&#34;_blank&#34;&gt;doi:10.1007/s10994-008-5057-7&lt;/a&gt; and the Markov blanket resampling from Su and Borsuk (2016) &lt;a href=&#34;http://jmlr.org/papers/v17/su16a.html&#34; target=&#34;_blank&#34;&gt;http://jmlr.org/papers/v17/su16a.html&lt;/a&gt;. It supports three priors: a prior controlling for structure complexity from Koivisto and Sood (2004) &lt;a href=&#34;http://dl.acm.org/citation.cfm?id=1005332.1005352&#34; target=&#34;_blank&#34;&gt;http://dl.acm.org/citation.cfm?id=1005332.1005352&lt;/a&gt;, an uninformative prior and a user-defined prior. The three main problems that can be addressed by this R package are selecting the most probable structure based on a cache of pre-computed scores, controlling for overfitting, and sampling the landscape of high scoring structures. It allows us to quantify the marginal impact of relationships of interest by marginalizing out over structures or nuisance dependencies. Structural MCMC seems an elegant and natural way to estimate the true marginal impact, so one can determine if it&amp;rsquo;s magnitude is big enough to consider as a worthwhile intervention.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.rstudio.com/web/packages/mcmcabn/index.html&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/mcmcabn&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Does toe clipping for genotyping interfere with later-in-life nociception in mice?</title>
      <link>/publication/frezel/</link>
      <pubDate>Wed, 24 Apr 2019 00:00:00 +0200</pubDate>
      
      <guid>/publication/frezel/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Progression and risk factors of pododermatitis in part-time group housed rabbit does in Switzerland</title>
      <link>/publication/ruchti2/</link>
      <pubDate>Mon, 11 Mar 2019 00:00:00 +0100</pubDate>
      
      <guid>/publication/ruchti2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Is a single unique Bayesian network enough to accurately represent your data?</title>
      <link>/publication/mcmcabn/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0100</pubDate>
      
      <guid>/publication/mcmcabn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Revealing the structure of the associations between housing system, facilities, management and welfare of commercial laying hens using Additive Bayesian Networks</title>
      <link>/publication/comin/</link>
      <pubDate>Wed, 09 Jan 2019 00:00:00 +0100</pubDate>
      
      <guid>/publication/comin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comparison between Suitable Priors for Additive Bayesian Networks</title>
      <link>/publication/catabn/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0200</pubDate>
      
      <guid>/publication/catabn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pododermatitis in group housed rabbit does in Switzerland – prevalence, severity and risk factors</title>
      <link>/publication/ruchti1/</link>
      <pubDate>Mon, 30 Jul 2018 00:00:00 +0200</pubDate>
      
      <guid>/publication/ruchti1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Information-Theoretic Scoring Rules to Learn Additive Bayesian Network Applied to Epidemiology</title>
      <link>/publication/mleabn/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0200</pubDate>
      
      <guid>/publication/mleabn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A battle to the death</title>
      <link>/post/pval/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/pval/</guid>
      <description>&lt;p&gt;&lt;em&gt;It is unanimously agreed that statistics depends somehow on probability. But, as to what probability is and how it is connected with statistics, there has seldom been such complete disagreement and breakdown of communication since the Tower of Babel.&lt;/em&gt; Savage, The Foundations of Statistics (1972)&lt;/p&gt;
&lt;p&gt;Recentely, I had to give a presentation about &lt;strong&gt;P value&lt;/strong&gt; and I discovered during the preparation of this talk a &lt;strong&gt;battle to the death&lt;/strong&gt; within statistics. It is enough unique to be reported and commented.&lt;/p&gt;
&lt;p&gt;A little bit of &lt;a href=&#34;https://en.wikipedia.org/wiki/History_of_statistics&#34;&gt;history of statistics&lt;/a&gt;, between the 18th to the 19th century, Bernoulli, Bayes, Laplace, Boole, Venn and others developed lots of ideas about probability and statistics. At this time &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Statistical_inference&#34;&gt;statistical inference&lt;/a&gt;&lt;/strong&gt; was &lt;em&gt;Bayesian&lt;/em&gt;. Then it required prior probability. &lt;a href=&#34;https://en.wikipedia.org/wiki/Ronald_Fisher&#34;&gt;Sir Ronald Fisher&lt;/a&gt; didn’t want to specify a prior, so he constructed a new framework for statistical inference around 1920s. Part of this is what he called significance testing and significance levels, which we now call P-values. Jerzy Neyman and Egon Pearson “extended” Fisher’s ideas and wrote about hypothesis testing (1930s).&lt;/p&gt;
&lt;p&gt;Fisher wanted a way to test the results from experiments. The motivation questions he had were: How does the data match to my hypothesis (i.e the assumed model)? But he still refused to assume a prior probability. On the contrary Neyman does not assume many repeated experiments from the same population. He wanted the researcher to have a tool to help evaluate the strength of evidence.&lt;/p&gt;
&lt;p&gt;Fisher and Neyman couldn’t resolve the differences between their ideas. They argued for 25 years until Fisher died in 1962. Fisher proposed a way to measure how likely the results of an experiment are under some assumptions. Neyman proposed to use cut off levels to decide whether the data matched to a hypothesis, with the cut offs chosen to limit errors.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>varrank: an R package for variable ranking based on mutual information with applications to observed systemic datasets</title>
      <link>/publication/varrank/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0200</pubDate>
      
      <guid>/publication/varrank/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reproducibility in Science</title>
      <link>/post/natruecommunication/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/natruecommunication/</guid>
      <description>&lt;p&gt;As a biostatistician I am particularly concerned by reproducibility in research (&lt;strong&gt;RR&lt;/strong&gt;). I try very hard to do reproducible research. It is often hard. Often this is not clear how to achieve &lt;strong&gt;RR&lt;/strong&gt;. Within our group, we had recently some discussions about &lt;strong&gt;RR&lt;/strong&gt;. Below is a small &lt;em&gt;personal&lt;/em&gt; manifesto for &lt;strong&gt;RR&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;manifesto-for-reproducible-research&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Manifesto for reproducible research&lt;/h1&gt;
&lt;p&gt;I believe that good science is made of trustable science. I believe that the most trustable academic research can only be achieved with a rigorous application of scientific methods. I believe that a minimal condition of the scientific methods is reproducibility of the research. While being viewed as obvious consent within Academia, in practice it requires extremely well organised scientists. Statistics is by nature an interdisciplinary effort and as many other disciplines it faces the reproducibility crisis. If one want to produce relevant, widely accessible and trustable scientific outputs one has to take it very seriously.&lt;/p&gt;
&lt;p&gt;I view the reproducible research approach as a comprehensive philosophy. It includes the individual research of academic group members but also external collaborations. An essential part of reproducibility is the transparency of data. Therefore I tried to use publicly available and trustable data wherever possible and feasible. Likewise, I make my data product openly accessible together with the necessary documentation.&lt;/p&gt;
&lt;p&gt;I believe that scripting is the optimal way to achieve reproducible workflow. In order to create easily reproducible software packages, I follow the dynamic programming approach, which is a method to solve large scale problems by atomising them into simple tasks. Using version control allows me to document changes, ensuring historical reproducibility and efficient collaboration. I pay a special attention to publish the necessary documentation together with my softwares.&lt;/p&gt;
&lt;p&gt;Producing and delivering reproducible code implies being as independent as possible of the user environment. This is why I use platform independent and open source programming languages. It also requires to produce well documented code that corresponds to commonly used code styles, which facilitates user readability. I believe that the tests used to develop code are part of the code and then should be published.&lt;/p&gt;
&lt;p&gt;I believe that complex scientific challenges require large collaborative work to be tackled. I believe that reproducibility is of higher importance there. This is why I aim at working in an organised manner which means to be sparse with the documents I exchange to ensure efficient partnership. I believe that continuous integration is a way to save precious time.&lt;/p&gt;
&lt;p&gt;Reproducible research is a fast moving research area and I invest time for scooting new approaches and exchange with other research groups.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Reproducibility in Science</title>
      <link>/post/repro/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/repro/</guid>
      <description>&lt;p&gt;As a biostatistician I am particularly concerned by reproducibility in research (&lt;strong&gt;RR&lt;/strong&gt;). I try very hard to do reproducible research. It is often hard. Often this is not clear how to achieve &lt;strong&gt;RR&lt;/strong&gt;. Within our group, we had recently some discussions about &lt;strong&gt;RR&lt;/strong&gt;. Below is a small &lt;em&gt;personal&lt;/em&gt; manifesto for &lt;strong&gt;RR&lt;/strong&gt;.&lt;/p&gt;
&lt;div id=&#34;manifesto-for-reproducible-research&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Manifesto for reproducible research&lt;/h1&gt;
&lt;p&gt;I believe that good science is made of trustable science. I believe that the most trustable academic research can only be achieved with a rigorous application of scientific methods. I believe that a minimal condition of the scientific methods is reproducibility of the research. While being viewed as obvious consent within Academia, in practice it requires extremely well organised scientists. Statistics is by nature an interdisciplinary effort and as many other disciplines it faces the reproducibility crisis. If one want to produce relevant, widely accessible and trustable scientific outputs one has to take it very seriously.&lt;/p&gt;
&lt;p&gt;I view the reproducible research approach as a comprehensive philosophy. It includes the individual research of academic group members but also external collaborations. An essential part of reproducibility is the transparency of data. Therefore I tried to use publicly available and trustable data wherever possible and feasible. Likewise, I make my data product openly accessible together with the necessary documentation.&lt;/p&gt;
&lt;p&gt;I believe that scripting is the optimal way to achieve reproducible workflow. In order to create easily reproducible software packages, I follow the dynamic programming approach, which is a method to solve large scale problems by atomising them into simple tasks. Using version control allows me to document changes, ensuring historical reproducibility and efficient collaboration. I pay a special attention to publish the necessary documentation together with my softwares.&lt;/p&gt;
&lt;p&gt;Producing and delivering reproducible code implies being as independent as possible of the user environment. This is why I use platform independent and open source programming languages. It also requires to produce well documented code that corresponds to commonly used code styles, which facilitates user readability. I believe that the tests used to develop code are part of the code and then should be published.&lt;/p&gt;
&lt;p&gt;I believe that complex scientific challenges require large collaborative work to be tackled. I believe that reproducibility is of higher importance there. This is why I aim at working in an organised manner which means to be sparse with the documents I exchange to ensure efficient partnership. I believe that continuous integration is a way to save precious time.&lt;/p&gt;
&lt;p&gt;Reproducible research is a fast moving research area and I invest time for scooting new approaches and exchange with other research groups.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
