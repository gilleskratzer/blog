<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>/post/</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Gilles Kratzer</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A battle to the death</title>
      <link>/post/pval/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/pval/</guid>
      <description>It is unanimously agreed that statistics depends somehow on probability. But, as to what probability is and how it is connected with statistics, there has seldom been such complete disagreement and breakdown of communication since the Tower of Babel. Savage, The Foundations of Statistics (1972)
Recentely, I had to give a presentation about P value and I discovered during the preparation of this talk a battle to the death within statistics.</description>
    </item>
    
    <item>
      <title>Reproducibility in Science</title>
      <link>/post/natruecommunication/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/natruecommunication/</guid>
      <description>As a biostatistician I am particularly concerned by reproducibility in research (RR). I try very hard to do reproducible research. It is often hard. Often this is not clear how to achieve RR. Within our group, we had recently some discussions about RR. Below is a small personal manifesto for RR.
Manifesto for reproducible research I believe that good science is made of trustable science. I believe that the most trustable academic research can only be achieved with a rigorous application of scientific methods.</description>
    </item>
    
    <item>
      <title>Reproducibility in Science</title>
      <link>/post/repro/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/repro/</guid>
      <description>As a biostatistician I am particularly concerned by reproducibility in research (RR). I try very hard to do reproducible research. It is often hard. Often this is not clear how to achieve RR. Within our group, we had recently some discussions about RR. Below is a small personal manifesto for RR.
Manifesto for reproducible research I believe that good science is made of trustable science. I believe that the most trustable academic research can only be achieved with a rigorous application of scientific methods.</description>
    </item>
    
    <item>
      <title>Stochastic SIR</title>
      <link>/post/gillespie/</link>
      <pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/gillespie/</guid>
      <description>I did my Master Thesis, about Infectious Disease Inference, at Stockholm University in the departement of Mathematical Statistics. Infectious disease inference is a very interesting and challenging research subject. Moreover this domain of statistcs is at the edge between statistics and simulations (which made my background in physics very relevant and suddenly make my stats and physics master start resonating). I think that this was my very first contact with computational statistics and it gave me the desir to learn more!</description>
    </item>
    
    <item>
      <title>Google Ngram</title>
      <link>/post/ngram/</link>
      <pubDate>Fri, 30 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/ngram/</guid>
      <description>The Google Ngram Viewer, started in December 2010, is an online search engine that returns the yearly relative frequency of a set of words, found in a selected printed sources, called corpus of books, between 1500 and 2016 (many language available). More specifically, it returns the relative frequency of the yearly ngram (continuous set of n words. For example, I is a 1-gram and I am is a 2-grams). This means that if you search for one word (called unigram), you get the percentage of this word to all the other word found in the corpus of books for a certain year.</description>
    </item>
    
    <item>
      <title>abn use accross the world?</title>
      <link>/post/abn_used/</link>
      <pubDate>Sat, 03 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/abn_used/</guid>
      <description>This post is highly inspired by this post from R-Bloggers and my previous post. Again the necessary code is available here.
As maintenair of an R package, it is always interesting to know if it is used and by whom? This post shows some plots to asses R package usage.
I started by a small review to list the similar other R packages. I found that bnlearn, deal and grbase are comparable to abn.</description>
    </item>
    
    <item>
      <title>When do R programmers work?</title>
      <link>/post/download/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>/post/download/</guid>
      <description>This post is highly inspired by this post and this post. Here is the necessary code to produce those graphs (be aware that it is time and memory consuming!).
On June 10 2013, RStudio provides CRAN mirror logs download from 2012-10-01. Then it is possible to analyze this rich and huge amount of data. On an individual level, one can track the popularity of their (preferred package). Here one can track the number of download of the three most downloaded R packages.</description>
    </item>
    
  </channel>
</rss>